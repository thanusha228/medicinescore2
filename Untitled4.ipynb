{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mHCePSC_yHXZ",
        "outputId": "f736a634-bd12-4d22-d095-ffeb088cd41d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ CSV generated! Shape: (1300, 13)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2093870a-b2c9-44fb-afab-c433708ebdfc\", \"medicine_hackathon_ready.csv\", 101637)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define diseases and medicines\n",
        "disease_meds = {\n",
        "    \"Allergy\": [\"Cetirizine\", \"Fexofenadine\", \"Loratadine\", \"Montelukast\"],\n",
        "    \"Diabetes\": [\"Metformin\", \"Insulin\", \"Glipizide\", \"Dapagliflozin\"],\n",
        "    \"Fever\": [\"Paracetamol\", \"Ibuprofen\", \"Aspirin\"],\n",
        "    \"Asthma\": [\"Salbutamol\", \"Budesonide\", \"Montelukast\"],\n",
        "    \"Blood Pressure\": [\"Amlodipine\", \"Losartan\", \"Telmisartan\", \"Atenolol\"],\n",
        "    \"Pain\": [\"Ibuprofen\", \"Diclofenac\", \"Naproxen\", \"Aspirin\"],\n",
        "}\n",
        "\n",
        "# Severity mapping (ensures different outputs)\n",
        "severity_map = {\n",
        "    \"Cetirizine\": 1.5, \"Fexofenadine\": 2.2, \"Loratadine\": 1.2, \"Montelukast\": 3.1,\n",
        "    \"Metformin\": 3.9, \"Insulin\": 4.5, \"Glipizide\": 3.2, \"Dapagliflozin\": 2.4,\n",
        "    \"Paracetamol\": 1.0, \"Ibuprofen\": 2.7, \"Aspirin\": 3.0,\n",
        "    \"Salbutamol\": 2.0, \"Budesonide\": 1.8,\n",
        "    \"Amlodipine\": 3.0, \"Losartan\": 2.2, \"Telmisartan\": 2.3, \"Atenolol\": 3.3,\n",
        "    \"Diclofenac\": 3.4, \"Naproxen\": 2.1,\n",
        "}\n",
        "\n",
        "# Generate 1300 rows\n",
        "rows = []\n",
        "for _ in range(1300):\n",
        "    disease = np.random.choice(list(disease_meds.keys()))\n",
        "    med = np.random.choice(disease_meds[disease])\n",
        "\n",
        "    rows.append([\n",
        "        med,\n",
        "        disease,\n",
        "        np.random.randint(80, 400),  # Average Price\n",
        "        np.random.randint(50, 350),  # Cheaper Alternative Price\n",
        "        severity_map.get(med, np.random.uniform(1,5)),  # Side Effect Severity\n",
        "        np.random.uniform(5, 9),     # Effectiveness Score\n",
        "        np.random.randint(60, 100),  # Alternative Availability Score\n",
        "        np.random.choice([0,1]),     # Chronic Use Flag\n",
        "        np.random.choice([0,1]),     # Hospital Visit Flag\n",
        "        np.random.choice([\"Child\",\"Adult\",\"Senior\"]),  # Age Group\n",
        "        np.random.choice([0,1]),     # Target Adherence Level\n",
        "        np.random.choice([\"Male\",\"Female\"]),  # Gender\n",
        "        \"Dataset\"                    # Source\n",
        "    ])\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(rows, columns=[\n",
        "    \"Medicine_Name\",\"Condition_Treated\",\"Average_Price\",\"Cheaper_Alternative_Price\",\n",
        "    \"Side_Effects_Severity\",\"Medicine_Effectiveness_Score\",\"Alternative_Availability_Score\",\n",
        "    \"Chronic_Use_Flag\",\"Hospital_Visit_Flag\",\"Age_Group\",\"Adherence_Level\",\"Gender\",\"Source\"\n",
        "])\n",
        "\n",
        "# Save CSV\n",
        "df.to_csv(\"/content/medicine_hackathon_ready.csv\", index=False)\n",
        "print(\"‚úÖ CSV generated! Shape:\", df.shape)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/medicine_hackathon_ready.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/medicine_hackathon_ready.csv\")\n",
        "\n",
        "# ---- Encode ALL categorical columns ----\n",
        "cat_cols = [\"Medicine_Name\", \"Condition_Treated\", \"Gender\", \"Age_Group\", \"Source\"]\n",
        "\n",
        "encoders = {}\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le  # store encoder\n",
        "\n",
        "# ---- Now all columns are numeric ----\n",
        "\n",
        "# Separate features & target\n",
        "X = df.drop(columns=[\"Adherence_Level\"])\n",
        "y = df[\"Adherence_Level\"]\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ---- Scale features ----\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ---- Train Logistic Regression Classifier ----\n",
        "model = LogisticRegression().fit(X_train_scaled, y_train)\n",
        "\n",
        "# ---- Save model & scaler ----\n",
        "pickle.dump(model, open(\"/content/medicine_model.pkl\", \"wb\"))\n",
        "pickle.dump(scaler, open(\"/content/medicine_scaler.pkl\", \"wb\"))\n",
        "pickle.dump(X.columns.tolist(), open(\"/content/medicine_features.pkl\", \"wb\"))\n",
        "\n",
        "# ---- Save each encoder separately ----\n",
        "for col, le in encoders.items():\n",
        "    pickle.dump(le, open(f\"/content/{col}_label_encoder.pkl\", \"wb\"))\n",
        "\n",
        "print(\"Pickle files generated! You can deploy now.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "minThz3BzW5G",
        "outputId": "9f03063c-b794-4c2d-f1d9-f42e87d640d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle files generated! You can deploy now.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoDhDkDNzoev",
        "outputId": "a8104651-de46-488c-87e0-191085e012a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.4)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.52.2-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.52.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ---- Load pickles ----\n",
        "model = pickle.load(open(\"medicine_model.pkl\", \"rb\"))\n",
        "scaler = pickle.load(open(\"medicine_scaler.pkl\", \"rb\"))\n",
        "features = pickle.load(open(\"medicine_features.pkl\", \"rb\"))\n",
        "\n",
        "# ---- Load encoders ----\n",
        "enc_medicine = pickle.load(open(\"Medicine_Name_label_encoder.pkl\", \"rb\"))\n",
        "enc_condition = pickle.load(open(\"Condition_Treated_label_encoder.pkl\", \"rb\"))\n",
        "enc_gender = pickle.load(open(\"Gender_label_encoder.pkl\", \"rb\"))\n",
        "enc_agegroup = pickle.load(open(\"Age_Group_label_encoder.pkl\", \"rb\"))\n",
        "enc_source = pickle.load(open(\"Source_label_encoder.pkl\", \"rb\"))\n",
        "\n",
        "# ---- Load dataset ----\n",
        "df = pd.read_csv(\"medicine_hackathon_ready.csv\")\n",
        "\n",
        "st.set_page_config(page_title=\"Medicine Truth Label AI\", layout=\"centered\")\n",
        "st.title(\"ü©∫ Medicine Truth Label AI\")\n",
        "\n",
        "st.subheader(\"Enter details manually\")\n",
        "\n",
        "# ---- Direct user inputs ----\n",
        "user_age = st.number_input(\"Enter Age\", 1, 120, step=1)\n",
        "user_gender = st.text_input(\"Enter Gender (Male/Female)\")\n",
        "user_disease = st.text_input(\"Enter Disease/Condition\")\n",
        "user_medicine = st.text_input(\"Enter Medicine Name\")\n",
        "\n",
        "# Normalize Gender text safely\n",
        "if user_gender:\n",
        "    user_gender = user_gender.strip().capitalize()\n",
        "    if user_gender not in [\"Male\", \"Female\"]:\n",
        "        st.error(\"‚ö† Please enter gender exactly as: Male or Female\")\n",
        "        st.stop()\n",
        "\n",
        "# ---- Button action ----\n",
        "if st.button(\"Analyze Medicine\"):\n",
        "    try:\n",
        "        # Encode categorical inputs\n",
        "        med_encoded = enc_medicine.transform([user_medicine])[0]\n",
        "        disease_encoded = enc_condition.transform([user_disease])[0]\n",
        "        gender_encoded = enc_gender.transform([user_gender])[0]\n",
        "\n",
        "        # Build input for model (stable, not random)\n",
        "        input_data = []\n",
        "        for f in features:\n",
        "            if f == \"Medicine_Name\":\n",
        "                input_data.append(med_encoded)\n",
        "            elif f == \"Condition_Treated\":\n",
        "                input_data.append(disease_encoded)\n",
        "            elif f == \"Gender\":\n",
        "                input_data.append(gender_encoded)\n",
        "            elif f == \"Age\":\n",
        "                input_data.append(user_age)\n",
        "            elif f == \"Age_Group\":\n",
        "                input_data.append(enc_agegroup.transform([user_age])[0])\n",
        "            elif f == \"Source\":\n",
        "                input_data.append(enc_source.transform([\"Dataset\"])[0])\n",
        "            else:\n",
        "                input_data.append(df[f].mean())  # only for least impactful numeric fields\n",
        "\n",
        "        df_input = pd.DataFrame([input_data], columns=features)\n",
        "        scaled = scaler.transform(df_input)\n",
        "\n",
        "        # Predict classification (0 or 1)\n",
        "        pred = model.predict(scaled)[0]\n",
        "\n",
        "        # ---- Classification result ----\n",
        "        if pred == 1:\n",
        "            st.success(\"Adherence Prediction: Good (Low Risk)\")\n",
        "        else:\n",
        "            st.error(\"Adherence Prediction: Poor (High Risk) ‚ö†\")\n",
        "\n",
        "        # ---- Medicine comparison for same disease ----\n",
        "        st.subheader(f\"üíä Personalized medicine comparison for disease: {user_disease}\")\n",
        "\n",
        "        disease_df = df[df[\"Condition_Treated\"] == user_disease]\n",
        "\n",
        "        if disease_df.empty:\n",
        "            st.error(\"‚ùó No medicines found for this disease!\")\n",
        "        else:\n",
        "            comparison = disease_df.groupby(\"Medicine_Name\").agg({\n",
        "                \"Side_Effects_Severity\": \"mean\",\n",
        "                \"Average_Price\": \"mean\",\n",
        "                \"Medicine_Effectiveness_Score\": \"mean\",\n",
        "                \"Dosage_mg\": \"mean\"\n",
        "            }).round(1)\n",
        "\n",
        "            comparison.rename(columns={\n",
        "                \"Side_Effects_Severity\": \"Avg_SideEffect_Risk\",\n",
        "                \"Average_Price\": \"Avg_Price (‚Çπ)\",\n",
        "                \"Medicine_Effectiveness_Score\": \"Avg_Effectiveness\",\n",
        "                \"Dosage_mg\": \"Avg_Dosage_mg\"\n",
        "            }, inplace=True)\n",
        "\n",
        "            # Sort by side effect severity (ascending = safest first)\n",
        "            comparison = comparison.sort_values(by=\"Avg_SideEffect_Risk\")\n",
        "            st.dataframe(comparison)\n",
        "\n",
        "            # Summary for medicines of same disease\n",
        "            st.subheader(\"üí° Medicine Summary:\")\n",
        "            for med, row in comparison.iterrows():\n",
        "                risk = row[\"Avg_SideEffect_Risk\"]\n",
        "                if risk <= 2:\n",
        "                    msg = \"Mild side effects, safer option\"\n",
        "                elif risk <= 3.5:\n",
        "                    msg = \"Medium side effects, monitor your health\"\n",
        "                else:\n",
        "                    msg = \"Strong side effects, be careful!\"\n",
        "                st.write(f\"- {med}: {msg}\")\n",
        "\n",
        "        # ---- Chatbot note ----\n",
        "        st.subheader(\"ü§ñ Lifestyle Recommendations\")\n",
        "        st.info(\"Lifestyle, diet plans, do‚Äôs/don‚Äôts, tips, and motivation will be generated using chatbot later.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"‚ö† Error: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze7778SjzddJ",
        "outputId": "1554680a-b769-427a-e26f-c2684cbb73d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req = \"\"\"streamlit\n",
        "pandas\n",
        "scikit-learn\n",
        "numpy\"\"\"\n",
        "\n",
        "with open(\"/content/requirements.txt\", \"w\") as f:\n",
        "    f.write(req)\n",
        "\n",
        "print(\"requirements.txt created!\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/requirements.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "eau8v0qF0DMh",
        "outputId": "8f98ba8c-d5eb-4773-c8f2-072c6816c377"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "requirements.txt created!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_149fb9a8-1cb9-46b3-8b35-ef1ba1b30d1f\", \"requirements.txt\", 35)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}